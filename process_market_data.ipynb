{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link marketing data with S&P500 and calculate sigma(mainly)\n",
    "## link with s&p500\n",
    "- Return_with_delist.csv is from former work\n",
    "- sp_500.csv is downloaded from web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret = pd.read_csv('data/Return_with_delist.csv')\n",
    "sp500 =pd.read_csv('data/sp_500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate mdate ,that is : translate the date int he form yyyymm\n",
    "def mdate(x):\n",
    "    x = str(x)\n",
    "    strp = datetime.datetime.strptime(x,'%Y%m%d')\n",
    "    year = strp.year\n",
    "    month =strp.month\n",
    "    mdate = year*100 + month\n",
    "    return mdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merge sp500 with the return_with_delist \n",
    "sp500_mdate = map(mdate,sp500['DATE'])\n",
    "sp500['mdate'] =sp500_mdate\n",
    "sp500 = sp500.drop('DATE',axis = 1)\n",
    "join = pd.merge(ret,sp500,on='mdate',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#replace the original price with the absolute value of it,for future use\n",
    "def abs_try(x,y):\n",
    "    if pd.notnull(x):\n",
    "        return abs(y) \n",
    "prc_abs=map(abs_try,join['RET'],join['PRC'])\n",
    "join.drop('PRC',axis =1)\n",
    "join['PRC'] = prc_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a function to transfer the return into float type, if it's null , replace it with zero\n",
    "def transfloat(x):\n",
    "    try:\n",
    "        x = float(x)\n",
    "        return x\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#replace the original return with the float type one\n",
    "market = join\n",
    "RET = map(transfloat,market['RET'])\n",
    "market.drop('RET',axis =1)\n",
    "market['RET'] = RET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "market.columns = [u'DATE', u'RET', u'SHROUT', u'mdate', u'PRC', u'PERMNO', u'CUSIP',\n",
    "       u'DLSTDT', u'DLSTCD', u'DLPRC', u'DLRET', u'vwretd', u'vwretx',\n",
    "       u'ewretd', u'ewretx', u'sprtrn', u'totval', u'totcnt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate sigma\n",
    "- sigma is the zero-centered variance for a period of time\n",
    "- in this section , we calculated the variance of the last 3 months as the volatitily of the current month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate the date after a certain lag\n",
    "def dat_lag(x,lagtime):\n",
    "    time_after_lag_1 = x - datetime.timedelta(days = lagtime)\n",
    "    date_lag_1m = time_after_lag_1.year * 100 + time_after_lag_1.month\n",
    "    return date_lag_1m\n",
    "def lag(lagtime1,lagtime2,lagtime3,datlist):\n",
    "    lag1 = [lagtime1] * len(datlist)\n",
    "    lag2 = [lagtime2] * len(datlist)\n",
    "    lag3 = [lagtime3] * len(datlist)\n",
    "    return lag1,lag2,lag3\n",
    "# calculate the zero-centered sigma for the a certain period of time\n",
    "def df_sigma(lagtime1,lagtime2,lagtime3,df):\n",
    "    df['DATE'] = df['DATE'].astype(str)\n",
    "    dat = map(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d'), df['DATE'])\n",
    "    lag1,lag2,lag3 = lag(lagtime1,lagtime2,lagtime3,dat)\n",
    "    lag1mon = map(dat_lag,dat,lag1)\n",
    "    lag2mon = map(dat_lag,dat,lag2)\n",
    "    lag3mon = map(dat_lag,dat,lag3)\n",
    "    df['lag1mon'] = lag1mon\n",
    "    df['lag2mon'] = lag2mon\n",
    "    df['lag3mon'] = lag3mon\n",
    "    df_lag1 = df.loc[:,['PERMNO','RET','lag1mon']]\n",
    "    df_lag2 = df.loc[:,['PERMNO','RET','lag2mon']]\n",
    "    df_lag3 = df.loc[:,['PERMNO','RET','lag3mon']]\n",
    "    df_lag1.columns = [u'PERMNO', u'RET1m', u'mdate']\n",
    "    df_lag2.columns = [u'PERMNO', u'RET2m', u'mdate']\n",
    "    df_lag3.columns = [u'PERMNO', u'RET3m', u'mdate']\n",
    "    df_join1 = pd.merge(df,df_lag1,on = ['PERMNO','mdate'],how = 'inner')\n",
    "    df_join2 = pd.merge(df_join1,df_lag2,on = ['PERMNO','mdate'],how = 'inner')\n",
    "    df_join3 = pd.merge(df_join2,df_lag3,on = ['PERMNO','mdate'],how = 'inner')\n",
    "    sigma = map(lambda x,y,z:np.sqrt((x*x+y*y+z*z)/3),df_join3['RET1m'],df_join3['RET2m'],df_join3['RET3m'])\n",
    "    df_join3['sigma'] = sigma\n",
    "    return df_join3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "market = df_sigma(31,62,93,market)#calculate the sigma for the last 3 months\n",
    "market= market.drop(['RET1m','RET2m','RET3m',u'lag1mon',u'lag2mon',  u'lag3mon'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##set the null value in column(sigma) to 0##\n",
    "alist = market['sigma'].isnull()\n",
    "alist = np.array(alist)\n",
    "sigma = np.array(market['sigma'])\n",
    "sigma[alist] = 0\n",
    "market.drop('sigma',axis = 1)\n",
    "market['sigma'] = sigma\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "market.to_csv('market_raw.csv')#write to market_raw.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# annulized monthly data and calculate several features\n",
    "## anualize monthly data\n",
    "- for for 'ret' and 'vwretd', we used factorial(ret) and factorial(vwretd)\n",
    "- for the rest , we use average(rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw = pd.read_csv('data/market_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select a certain companyâ€˜s dataframe\n",
    "def get_df(ret,permno):\n",
    "    df = ret[ret['PERMNO'] == permno]\n",
    "    return df\n",
    "#identify the year\n",
    "def indexer(df):\n",
    "    c = df.groupby('fyear').apply(list)\n",
    "    d = c.keys()\n",
    "    return d\n",
    "#for return and vwretd, we need to calculate the floor of the 12 months, like Rm1*Rm2*...Rm12\n",
    "def ret(df,column):\n",
    "    grouped = df.groupby('fyear')[column].apply(np.array)\n",
    "    value = grouped.values\n",
    "    a = [i.resize((1,12),refcheck = False) for i in value]\n",
    "    aa = [np.squeeze(i) for i in value]\n",
    "    aaplu1 = [i+1 for i in aa]\n",
    "    ret = [np.prod(i) for i in aaplu1]\n",
    "    return ret\n",
    "#calculate the average sigma for a year\n",
    "def sigma(df): \n",
    "    grouped = df.groupby('fyear')['RET'].apply(np.array)\n",
    "    value = grouped.values\n",
    "    a = [i.resize((1,12),refcheck = False) for i in value]\n",
    "    aa = [np.squeeze(i) for i in value]\n",
    "    dot = [np.dot(i,i)/12 for i in aa]    \n",
    "    return dot\n",
    "#average a year's value\n",
    "def average(df,column):\n",
    "    grouped = df.groupby('fyear')[column].apply(np.array)\n",
    "    value = grouped.values\n",
    "    averaged = [np.sum(i)/12 for i in value]\n",
    "    return averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dlst(df):#to detect if there is a delist in a year\n",
    "    grouped = df.groupby('fyear')['delist'].apply(np.array)\n",
    "    value = grouped.values\n",
    "    de = map(lambda x:np.sum(x),value)\n",
    "    return de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_permno(dataframe,permno):#calculate the dataframe for a certain company\n",
    "    df = get_df(dataframe,permno)\n",
    "    INDEXER = indexer(df)\n",
    "    prc = average(df,'prc2')\n",
    "    totval = average(df,'totval')\n",
    "    MKET = average(df,'mket')\n",
    "    SIGMA = sigma(df)\n",
    "    RET = ret(df,'RET')\n",
    "    vwretd = ret(df,'vwretd')\n",
    "    DELIST = dlst(df)\n",
    "    PERMNO = [permno] * len(INDEXER)\n",
    "    dat = pd.DataFrame({'fyear':INDEXER,\n",
    "                        'PERMNO':PERMNO,\n",
    "                        'PRC':prc,\n",
    "                        'totval':totval,\n",
    "                        'sigma':SIGMA,\n",
    "                        'RET':RET,\n",
    "                        'vwretd':vwretd,\n",
    "                        'mket': MKET,\n",
    "                        'DELISTorNOT':DELIST})\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_final(dataframe):# calculation for all the companies\n",
    "    origin = merge_permno(dataframe,10000)\n",
    "    for i in range(0,len(permno_list)):\n",
    "        tmp = merge_permno(market,permno_list[i])\n",
    "        origin =origin.append(tmp)\n",
    "    return origin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate several features\n",
    "- prc2,mkt,exrcamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate the feature prc2\n",
    "def price2(price):\n",
    "    if price>15:\n",
    "        prc2 = 15\n",
    "    else:\n",
    "        prc2 = price\n",
    "    prc2 = np.log(prc2)\n",
    "    return prc2\n",
    "def prc2_map(dataset):\n",
    "    prc2_result= map(price2,dataset['PRC'])\n",
    "    return prc2_result\n",
    "#calculate the feature mkt\n",
    "def mkt(prc,shrout):\n",
    "    equity = prc * shrout\n",
    "    mket = equity/1000\n",
    "    return mket\n",
    "def mkt_map(dataset):\n",
    "    mkt_result = map(mkt,dataset['PRC'],dataset['SHROUT'])\n",
    "    return mkt_result\n",
    "prc2 = prc2_map(raw)\n",
    "mket = mkt_map(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate the feature exrcamp = LOG(1+ret)-LOG(1+vwretd)\n",
    "def func(ret,vwretd):\n",
    "    tmp = np.log(1+ret) - np.log(1+vwretd)\n",
    "    return tmp\n",
    "def exrcamp(dataset):\n",
    "    result = map(func,dataset['RET'],dataset['vwretd'])\n",
    "    return result\n",
    "exrca = exrcamp(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw['prc2']=prc2\n",
    "raw['mket']=mket\n",
    "raw['excamp']=exrca\n",
    "market = raw[raw['mket'].notnull()]\n",
    "market =market[market['excamp'].notnull()]\n",
    "market = market.fillna(0)\n",
    "delist = map(deornot,market['DLSTCD'])\n",
    "market.columns=[u'Unnamed: 0', u'DATE', u'RET', u'SHROUT', u'mdate', u'PRC', u'PERMNO',\n",
    "       u'cusip', u'DLSTDT', u'DLSTCD', u'DLPRC', u'DLRET', u'vwretd',\n",
    "       u'vwretx', u'ewretd', u'ewretx', u'sprtrn', u'totval', u'totcnt',\n",
    "       u'prc2', u'mket', u'excamp', u'delist']\n",
    "date = map(lambda x:pd.to_datetime(x),market['DATE'])\n",
    "year = map(lambda x:x.year, date)\n",
    "market['fyear'] = year\n",
    "market['delist'] = delist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "permno_list = market['PERMNO'].unique()\n",
    "final = merge_final(market)#get the final anualized dataframe\n",
    "final.to_csv('anualized_marketing_data.csv')#write to anulized_market_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust the marketing data\n",
    "- because in former work , the delist label of a delisted company is 1 for every fiscal year, in this section ,for a certain delisted company, we will set the delist label for the last year to 1 and rest to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mkt = pd.read_csv('data/anualized_marketing_data.csv')\n",
    "mkt = mkt.drop('Unnamed: 0',axis=1)\n",
    "mkt.columns=[u'DELISTorNOT', u'PERMNO', u'PRC', u'RET', u'mket', u'sigma', u'totval',\n",
    "       u'vwretd', u'fyear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#because from the former work ,value in DELISTorNOT is range from 0-12, here we need to \n",
    "#create a new feature D to denote whether it is delisted or not\n",
    "def D_mkt(lis):# transform from '0' and '1-12' as '0' or '1'\n",
    "    if lis == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "d_mkt = map(D_mkt,mkt['DELISTorNOT'])\n",
    "mkt['D'] = d_mkt\n",
    "mkt_isin = mkt[mkt['D'] == 1]\n",
    "mkt_notin= mkt[mkt['D'] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check if the year is the latest one,if it is ,return 1, if it is not ,return 0\n",
    "def year_zero(newest,year): \n",
    "    if year < newest:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "#before, for a delisted company , D=1 for all the fyear, here , we only set the latest one --\n",
    "# i.e. the year it is delisted -- as 1, set rest as 0\n",
    "def firm_zero(onefirm):\n",
    "    maxn = max(onefirm['fyear'])\n",
    "    newest = [maxn]*len(onefirm)\n",
    "    ddd = map(year_zero,newest,onefirm['fyear'])\n",
    "    onefirm['D'] = ddd\n",
    "    return onefirm   \n",
    "#select a specific firm by permno\n",
    "def get_firm(dataset,permno):\n",
    "    firmdf = dataset[dataset['PERMNO'] == permno]\n",
    "    return firmdf\n",
    "def whole_zero(isin):# only let the last D be 1, others 0\n",
    "    origin = isin['PERMNO'].unique()\n",
    "    first = origin[0]\n",
    "    permno_list = origin[1:]\n",
    "    firstfirm = get_firm(isin,first)\n",
    "    firstdf = firm_zero(firstfirm)\n",
    "    for i in range(0,len(permno_list)):\n",
    "        firm = get_firm(isin,permno_list[i])\n",
    "        firmdf = firm_zero(firm)\n",
    "        firstdf=firstdf.append(firmdf)\n",
    "        \n",
    "    return firstdf\n",
    "mkt_isin_1= whole_zero(mkt_isin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mkt_final = mkt_isin_1.append(mkt_notin)\n",
    "mkt_final.to_csv('mkt_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
