{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input\n",
    "crsp.csv - marketing data by year     \n",
    "comp.csv - accounting data by year\n",
    "### output\n",
    "final_variables.csv with all features, bankruptcy indicator Y, and fyear, cusip, permno, permco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import time\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # display any variable and statement without a print in a cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_null_freq(df):\n",
    "    \"\"\" calculate null value # table for a df\n",
    "    :param df: dataframe to look into\n",
    "    :type df: pandas dataframe\n",
    "    :rtype: stdout\n",
    "    \"\"\"\n",
    "    df_lng = pd.melt(df)\n",
    "    null_variables = df_lng.value.isnull()\n",
    "    return pd.crosstab(df_lng.variable, null_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading data\n",
    "- combine two tables using 'Permno' and 'fyear'\n",
    "- combine comp data bk indicator 'dlrsn==2', 'dlrsn==3' and market data bk indicator 'D==1', get final bk indicator Y\n",
    "- output: datafram final, combined comp and market data from 1980-2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "market = pd.read_csv('data/crsp.csv')\n",
    "market = market.drop('Unnamed: 0',1)\n",
    "comp = pd.read_csv('data/comp.csv')\n",
    "#combine comp delist reason\n",
    "comp_delist = comp[(comp.dlrsn == 2) |(comp.dlrsn == 3)]\n",
    "comp_delist_gvkey = comp_delist['gvkey'].unique()\n",
    "# For any bk compnay in comp, only assigns the max_year of that company as Y = 1\n",
    "comp['y_from_comp'] = 0\n",
    "for gvkey in comp_delist_gvkey:\n",
    "    temp = comp[comp['gvkey'] == gvkey]\n",
    "    max_year = temp['fyear'].max()\n",
    "    comp.ix[(comp['gvkey']==gvkey) & (comp['fyear'] == max_year),'y_from_comp'] = 1\n",
    "final = comp.merge(market, on=['PERMNO','fyear'], how='inner')\n",
    "final['Y'] = 0\n",
    "final.ix[(final['D']==1) | (final['y_from_comp']==1),'Y'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>datadate</th>\n",
       "      <th>fyear</th>\n",
       "      <th>cusip</th>\n",
       "      <th>act</th>\n",
       "      <th>ap</th>\n",
       "      <th>at</th>\n",
       "      <th>ch</th>\n",
       "      <th>che</th>\n",
       "      <th>dlc</th>\n",
       "      <th>...</th>\n",
       "      <th>MVE</th>\n",
       "      <th>QA</th>\n",
       "      <th>dlrsn</th>\n",
       "      <th>sic</th>\n",
       "      <th>dldte</th>\n",
       "      <th>tic</th>\n",
       "      <th>cusip8</th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>PERMCO</th>\n",
       "      <th>y_from_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1005</td>\n",
       "      <td>19811031</td>\n",
       "      <td>1981</td>\n",
       "      <td>000370106</td>\n",
       "      <td>17.223</td>\n",
       "      <td>3.437</td>\n",
       "      <td>24.480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.412</td>\n",
       "      <td>3.468</td>\n",
       "      <td>...</td>\n",
       "      <td>13.383248</td>\n",
       "      <td>10.640</td>\n",
       "      <td>1</td>\n",
       "      <td>3724</td>\n",
       "      <td>19830131</td>\n",
       "      <td>ABA.2</td>\n",
       "      <td>00037010</td>\n",
       "      <td>61903</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1005</td>\n",
       "      <td>19801031</td>\n",
       "      <td>1980</td>\n",
       "      <td>000370106</td>\n",
       "      <td>10.275</td>\n",
       "      <td>2.806</td>\n",
       "      <td>15.504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.042</td>\n",
       "      <td>...</td>\n",
       "      <td>14.447997</td>\n",
       "      <td>6.977</td>\n",
       "      <td>1</td>\n",
       "      <td>3724</td>\n",
       "      <td>19830131</td>\n",
       "      <td>ABA.2</td>\n",
       "      <td>00037010</td>\n",
       "      <td>61903</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1005</td>\n",
       "      <td>19791031</td>\n",
       "      <td>1979</td>\n",
       "      <td>000370106</td>\n",
       "      <td>6.241</td>\n",
       "      <td>1.130</td>\n",
       "      <td>9.251</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.263</td>\n",
       "      <td>1.388</td>\n",
       "      <td>...</td>\n",
       "      <td>2.507499</td>\n",
       "      <td>3.806</td>\n",
       "      <td>1</td>\n",
       "      <td>3724</td>\n",
       "      <td>19830131</td>\n",
       "      <td>ABA.2</td>\n",
       "      <td>00037010</td>\n",
       "      <td>61903</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    gvkey  datadate  fyear      cusip     act     ap      at     ch    che  \\\n",
       "53   1005  19811031   1981  000370106  17.223  3.437  24.480    NaN  0.412   \n",
       "54   1005  19801031   1980  000370106  10.275  2.806  15.504    NaN  0.918   \n",
       "55   1005  19791031   1979  000370106   6.241  1.130   9.251  0.263  0.263   \n",
       "\n",
       "      dlc     ...             MVE      QA  dlrsn   sic     dldte    tic  \\\n",
       "53  3.468     ...       13.383248  10.640      1  3724  19830131  ABA.2   \n",
       "54  0.042     ...       14.447997   6.977      1  3724  19830131  ABA.2   \n",
       "55  1.388     ...        2.507499   3.806      1  3724  19830131  ABA.2   \n",
       "\n",
       "      cusip8  PERMNO  PERMCO  y_from_comp  \n",
       "53  00037010   61903      11            0  \n",
       "54  00037010   61903      11            0  \n",
       "55  00037010   61903      11            0  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp[comp['cusip8'] == '00037010']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#handle missing values in final data\n",
    "del final['ffo']\n",
    "final = final.dropna(subset=['at'])\n",
    "final = final.dropna(subset=['seq'])\n",
    "final = final.dropna(subset=['lt'])\n",
    "final['ni'] = final['ni'].fillna(0)\n",
    "final['sale'] = final['sale'].fillna(0)\n",
    "final['oiadp'] = final['oiadp'].fillna(0)\n",
    "final['ebit'] = final['ebit'].fillna(0)\n",
    "final['dp'] = final['dp'].fillna(0)\n",
    "final['re'] = final['re'].fillna(0)\n",
    "final['lct'] = final['lct'].fillna(0)\n",
    "final['ch'] = final['ch'].fillna(0)\n",
    "final['lt'] = final['lt'].fillna(0)\n",
    "final['QA'] = final['QA'].fillna(0)\n",
    "final['act'] = final['act'].fillna(0)\n",
    "final['wcap'] = final['wcap'].fillna(0)\n",
    "final['invt'] = final['invt'].fillna(0)\n",
    "final['ap'] = final['ap'].fillna(0)\n",
    "final['invch'] = final['invch'].fillna(0)\n",
    "final['che'] = final['che'].fillna(0)\n",
    "final['dlc'] = final['dlc'].fillna(0)\n",
    "final['dltt'] = final['dltt'].fillna(0)\n",
    "final['mib'] = final['mib'].fillna(0)\n",
    "final['BE'] = final['BE'].fillna(0)\n",
    "# remove the rows where lct is bigger than lt\n",
    "final['compare_lt_lct'] = final.apply(lambda x: 1 if x['lct']>x['lt'] else 0, axis = 1)\n",
    "final.drop(final[final.compare_lt_lct==1].index,inplace = True)\n",
    "#create market value of total asset, mta\n",
    "final['mta'] = final['mket']+final['lt']+final['mib']\n",
    "\n",
    "# all the functions to calculate certain variables\n",
    "def pretty_division(x,y):\n",
    "    if y == 0:\n",
    "        return 0\n",
    "    return x/y\n",
    "def NIAT(df):\n",
    "    return pretty_division(df['ni'],df['at'])\n",
    "def NISALE(df):\n",
    "    return pretty_division(df['ni'],df['sale'])\n",
    "def OIADPAT(df):\n",
    "    return pretty_division(df['oiadp'],df['at'])\n",
    "def OIADPSALE(df):\n",
    "    return pretty_division(df['oiadp'],df['sale'])\n",
    "def EBITAT(df):\n",
    "    return pretty_division(df['ebit'],df['at'])\n",
    "def EBITDPAT(df):\n",
    "    return pretty_division((df['ebit']+df['dp']),df['at'])\n",
    "def EBITSALE(df):\n",
    "    return pretty_division(df['ebit'],df['sale'])\n",
    "def SEQAT(df):\n",
    "    return pretty_division(df['seq'],df['at'])\n",
    "def REAT(df):\n",
    "    return pretty_division(df['re'],df['at'])\n",
    "def LCTAT(df):\n",
    "    return pretty_division(df['lct'],df['at'])\n",
    "def LCTCHAT(df):\n",
    "    return pretty_division((df['lct']-df['ch']),df['at'])\n",
    "def LTAT(df):\n",
    "    return pretty_division(df['lt'],df['at'])\n",
    "def CHAT(df):\n",
    "    return pretty_division(df['ch'],df['at'])\n",
    "def CHLCT(df):\n",
    "    return pretty_division(df['ch'],df['lct'])\n",
    "def QALCT(df):\n",
    "    return pretty_division(df['QA'],df['lct'])\n",
    "def ACTLCT(df):\n",
    "    return pretty_division(df['act'],df['lct'])\n",
    "def WCAPAT(df):\n",
    "    return pretty_division(df['wcap'],df['at'])\n",
    "def LCTLT(df):\n",
    "    return pretty_division(df['lct'],df['lt'])\n",
    "def INVTSALE(df):\n",
    "    return pretty_division(df['invt'],df['sale'])\n",
    "def SALEAT(df):\n",
    "    return pretty_division(df['sale'],df['at'])\n",
    "def APSALE(df):\n",
    "    return pretty_division(df['ap'],df['sale'])\n",
    "def INVCHINVT(df):\n",
    "    return pretty_division(df['invch'],df['invt'])\n",
    "def CASHAT(df):\n",
    "    return pretty_division(df['che'],df['at'])\n",
    "def FFOLT(df):\n",
    "    return pretty_division(df['ffo'],df['lt'])\n",
    "def LCTSALE(df):\n",
    "    return pretty_division(df['lct'],df['sale'])\n",
    "def RELCT(df):\n",
    "    return pretty_division(df['re'],df['lct'])\n",
    "def FAT(df):\n",
    "    return pretty_division((df['dlc']+0.5*df['dltt']),df['at'])\n",
    "def NIMTA(df):\n",
    "    return pretty_division(df['ni'],df['mta'])\n",
    "def LTMTA(df):\n",
    "    return pretty_division(df['lt'],df['mta'])\n",
    "def CASHMTA(df):\n",
    "    return pretty_division(df['che'],df['mta'])\n",
    "def RSIZE(df):\n",
    "    return np.log(pretty_division((1000*df['mket']),df['totval']))\n",
    "def EXCESS_RETURN(df):\n",
    "    return (np.log(1+df['RET']) - np.log(1+df['vwretd']))\n",
    "def MBE(df):\n",
    "    return pretty_division(df['mket'],(df['BE']+0.1*(df['mket']-df['BE'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating features: 2.03 minutes ---\n"
     ]
    }
   ],
   "source": [
    "#define a function get_variables() to get a df with all clean features and bankruptcy indicator Y\n",
    "def get_variables(df_raw):\n",
    "    df_variables = pd.DataFrame()\n",
    "    df_variables['Y'] = df_raw['Y']\n",
    "    df_variables['gvkey'] = df_raw['gvkey']\n",
    "    df_variables['datadate'] = df_raw['datadate']\n",
    "    df_variables['fyear'] = df_raw['fyear']\n",
    "    df_variables['cusip'] = df_raw['cusip']\n",
    "    df_variables['PERMNO'] = df_raw['PERMNO']\n",
    "    df_variables['PERMCO'] = df_raw['PERMCO']\n",
    "    #accounting\n",
    "    df_variables['NIAT'] = df_raw.apply(NIAT,axis=1)\n",
    "    df_variables['NISALE'] = df_raw.apply(NISALE,axis=1)\n",
    "    df_variables['OIADPAT'] = df_raw.apply(OIADPAT,axis=1)\n",
    "    df_variables['OIADPSALE'] = df_raw.apply(OIADPSALE,axis=1)\n",
    "    df_variables['EBITAT'] = df_raw.apply(EBITAT,axis=1)\n",
    "    df_variables['EBITDPAT'] = df_raw.apply(EBITDPAT,axis=1)\n",
    "    df_variables['EBITSALE'] = df_raw.apply(EBITSALE,axis=1)\n",
    "    df_variables['SEQAT'] = df_raw.apply(SEQAT,axis=1)\n",
    "    df_variables['REAT'] = df_raw.apply(REAT,axis=1)\n",
    "    df_variables['LCTAT'] = df_raw.apply(LCTAT,axis=1)\n",
    "    df_variables['LCTCHAT'] = df_raw.apply(LCTCHAT,axis=1)\n",
    "    df_variables['LTAT'] = df_raw.apply(LTAT,axis=1)\n",
    "    df_variables['LOGSALE'] = np.log(abs(df_raw['sale'])) # if sale is 0, logsale will be 0 here\n",
    "    df_variables['CHAT'] = df_raw.apply(CHAT,axis=1)\n",
    "    df_variables['CHLCT'] = df_raw.apply(CHLCT,axis=1)\n",
    "    df_variables['QALCT'] = df_raw.apply(QALCT,axis=1)\n",
    "    df_variables['ACTLCT'] = df_raw.apply(ACTLCT,axis=1)\n",
    "    df_variables['WCAPAT'] = df_raw.apply(WCAPAT,axis=1)\n",
    "    df_variables['LCTLT'] = df_raw.apply(LCTLT,axis=1)\n",
    "    df_variables['INVTSALE'] = df_raw.apply(INVTSALE,axis=1)\n",
    "    df_variables['SALEAT'] = df_raw.apply(SALEAT,axis=1)\n",
    "    df_variables['APSALE'] = df_raw.apply(APSALE,axis=1)\n",
    "    df_variables['LOGSALE'] = np.log(abs(df_raw['sale']))\n",
    "    df_variables['LOGAT'] = np.log(df_raw['at']) # if total asset is 0, logat will be 0 here\n",
    "    df_variables['INVCHINVT'] = df_raw.apply(INVCHINVT,axis=1)\n",
    "    df_variables['CASHAT'] = df_raw.apply(CASHAT,axis=1)\n",
    "    #df_variables['FFOLT'] = df_raw.apply(FFOLT,axis=1)\n",
    "    df_variables['LCTSALE'] = df_raw.apply(LCTSALE,axis=1)\n",
    "    df_variables['RELCT'] = df_raw.apply(RELCT,axis=1)\n",
    "    df_variables['FAT'] = df_raw.apply(FAT,axis=1)\n",
    "\n",
    "\n",
    "    # market\n",
    "    df_variables['SIGMA'] = df_raw['sigma']\n",
    "    df_variables['NIMTA'] = df_raw.apply(NIMTA,axis=1)\n",
    "    df_variables['LTMTA'] = df_raw.apply(LTMTA,axis=1)\n",
    "    df_variables['CASHMTA'] = df_raw.apply(CASHMTA,axis=1)\n",
    "    df_variables['PRICE'] = df_raw['PRC']\n",
    "    df_variables['RSIZE'] = df_raw.apply(RSIZE,axis=1)\n",
    "    df_variables['EXCESS_RETURN'] = df_raw.apply(EXCESS_RETURN,axis=1)\n",
    "    df_variables['MBE'] = df_raw.apply(MBE,axis=1)\n",
    "    return df_variables\n",
    "\n",
    "start_time = time.time()\n",
    "final_variable = get_variables(final)\n",
    "print(\"creating features: %s minutes ---\" % round(((time.time() - start_time)/60),2))\n",
    "final_variable.to_csv('data/final_variables.csv')\n",
    "#%time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean data\n",
    "### after calculation variables\n",
    "- 2 infinite variables due to logrithm of 0, logsale and logat\n",
    "- create table one_year, with Y and x one year before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182300, 43)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_variable = pd.read_csv('data/final_variables.csv')\n",
    "final_variable = final_variable.drop('Unnamed: 0',1)\n",
    "final_variable = final_variable.replace([np.inf,-np.inf],0)\n",
    "final_variable.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1162"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_variable['Y'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge 'Y' with the data one year before\n",
    "dat_tmp = final_variable.copy()\n",
    "dat_tmp['fyear'] = dat_tmp['fyear'] +1\n",
    "dat_tmp = dat_tmp.drop('Y',axis =1)\n",
    "Ys = final_variable[['fyear','gvkey','Y']]\n",
    "one_year = pd.merge(dat_tmp,Ys,how = 'inner',on=['fyear','gvkey'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one year model\n",
    "input files:    \n",
    "final_variables.csv    \n",
    "output:     \n",
    "logistic regression using L1 penalty, one-year time window     \n",
    "report in sample(1980-2007),out-of sample(2008-2015) roc_auc, accuracy_ratio = (roc_auc-0.5)*2 and deciles of bk  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1016"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_year['Y'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#seperate training and testing set:from tian's paper, training set is variables before 2003\n",
    "#testing set is variables after 2003\n",
    "train = one_year[one_year['fyear']<2008]\n",
    "test = one_year[one_year['fyear']>=2008]\n",
    "drop_list = ['gvkey','datadate','fyear','cusip','PERMNO','PERMCO']\n",
    "train = train.drop(drop_list,axis = 1)\n",
    "test = test.drop(drop_list,axis = 1)\n",
    "x_train = train.ix[:,0:-1]\n",
    "y_train = train.ix[:,-1]\n",
    "x_test = test.ix[:,0:-1]\n",
    "y_test = test.ix[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131708, 37)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# functions to report result\n",
    "def get_prob_auc(clf,x,y):\n",
    "    probas_= clf.predict_proba(x)\n",
    "    probas_=probas_[:,1]\n",
    "    fpr,tpr,thresholds = roc_curve(y,probas_)\n",
    "    roc_auc = roc_auc_score(y,probas_)\n",
    "    accuracy_ratio = (roc_auc-0.5)*2\n",
    "    return probas_,accuracy_ratio\n",
    "def tencile_table(test,p):\n",
    "    tenc_dat = pd.DataFrame({'y_true':test,'probability':p})\n",
    "    tenc_dat.sort('probability',axis = 0,ascending=False, inplace = True)\n",
    "    tenc_dat.index = range(0,len(tenc_dat))\n",
    "    y = tenc_dat['y_true']\n",
    "    point = float(len(tenc_dat))/10\n",
    "    point = int(round(point))\n",
    "    tenc = []\n",
    "    for i in range(0,10):\n",
    "        tenc.append(y[(i*point):((i+1)*point)])\n",
    "    tenc[9]=tenc[9].append(y[10*point:])\n",
    "    total = sum(y)\n",
    "    num_of_bkr = []\n",
    "    for j in range(0,10):\n",
    "        num_of_bkr.append(sum(tenc[j]))\n",
    "    tencile_bkr = np.array(num_of_bkr)\n",
    "    rate = tencile_bkr.astype(float)/total\n",
    "    tencile_result=pd.DataFrame({'Group':range(1,11),'Rate':rate})\n",
    "    return tencile_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use LogisticRegressionCV to find optimal C from logspace(-4,4), CV = 3, metric = AUC, C is the inverse of $\\lambda$\n",
    "- it will take about 160 mins to run, get optimal C = 0.359\n",
    "- choice of Cs, array([  1.00000000e-04,   7.74263683e-04,   5.99484250e-03,4.64158883e-02,   3.59381366e-01,   2.78255940e+00,2.15443469e+01,   1.66810054e+02,   1.29154967e+03,1.00000000e+04])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lgr = LogisticRegressionCV(Cs = np.logspace(-4,4,10),cv=3,\n",
    "                           penalty = 'l1',\n",
    "                          scoring='roc_auc',\n",
    "                          solver= 'liblinear',n_jobs = 2)\n",
    "fitmodel = lgr.fit(x_train,y_train)\n",
    "print(\"grid search to find optimal C: %s minutes ---\" % round(((time.time() - start_time)/60),2))\n",
    "#%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(lgr.C_)\n",
    "print(lgr.Cs_)\n",
    "print(lgr.Coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.359, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use logistic regression C = 0.359\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lg = LogisticRegression(C = 0.359,penalty='l1')\n",
    "lg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['PRICE', 'LCTCHAT', 'LTMTA', 'ACTLCT', 'INVCHINVT', 'SALEAT', 'QALCT', 'APSALE', 'LOGAT', 'RELCT', 'REAT', 'OIADPSALE', 'FAT', 'LOGSALE', 'CASHMTA', 'RSIZE', 'CASHAT', 'LCTLT', 'NIMTA', 'CHLCT', 'SIGMA', 'NISALE', 'EXCESS_RETURN', 'EBITDPAT', 'LCTSALE', 'WCAPAT', 'OIADPAT', 'LTAT', 'INVTSALE', 'NIAT', 'MBE'])\n"
     ]
    }
   ],
   "source": [
    "feature_name = x_train.columns\n",
    "model_coef = lg.coef_[0]\n",
    "selected_features = {}\n",
    "for idx,name in enumerate(feature_name):\n",
    "    if model_coef[idx] != 0:\n",
    "        selected_features[name] = model_coef[idx]\n",
    "#print (selected_features)\n",
    "print (selected_features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Group      Rate\n",
      "0      1  0.444688\n",
      "1      2  0.175246\n",
      "2      3  0.105148\n",
      "3      4  0.090909\n",
      "4      5  0.049288\n",
      "5      6  0.058050\n",
      "6      7  0.035049\n",
      "7      8  0.015334\n",
      "8      9  0.009858\n",
      "9     10  0.016429\n",
      "in-sample logistic regression accuracy ratio is 0.578781, auc is 0.789390\n"
     ]
    }
   ],
   "source": [
    "# in-sample logistic regression result \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "in_prob_,in_accuracy_ratio = get_prob_auc(lg, x_train,y_train)\n",
    "print (tencile_table(y_train,in_prob_))\n",
    "print ('in-sample logistic regression accuracy ratio is %f, auc is %f' %(in_accuracy_ratio, in_accuracy_ratio/2+0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Group      Rate\n",
      "0      1  0.388350\n",
      "1      2  0.223301\n",
      "2      3  0.184466\n",
      "3      4  0.077670\n",
      "4      5  0.038835\n",
      "5      6  0.009709\n",
      "6      7  0.009709\n",
      "7      8  0.019417\n",
      "8      9  0.019417\n",
      "9     10  0.029126\n",
      "out-sample logistic regression accuracy ratio is 0.578918, auc is 0.789459\n"
     ]
    }
   ],
   "source": [
    "# out-sample logistic regression result \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "out_prob_,out_accuracy_ratio = get_prob_auc(lg, x_test,y_test)\n",
    "print (tencile_table(y_test,out_prob_))\n",
    "print ('out-sample logistic regression accuracy ratio is %f, auc is %f' %(out_accuracy_ratio, out_accuracy_ratio/2+0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rfr = RandomForestClassifier()\n",
    "clf_rfr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Group  Rate\n",
      "0      1     1\n",
      "1      2     0\n",
      "2      3     0\n",
      "3      4     0\n",
      "4      5     0\n",
      "5      6     0\n",
      "6      7     0\n",
      "7      8     0\n",
      "8      9     0\n",
      "9     10     0\n",
      "in-sample random forest accuracy ratio is 0.998788, auc is 0.999394\n"
     ]
    }
   ],
   "source": [
    "# in-sample rfr result \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "in_prob_,in_accuracy_ratio = get_prob_auc(clf_rfr, x_train,y_train)\n",
    "print (tencile_table(y_train,in_prob_))\n",
    "print ('in-sample random forest accuracy ratio is %f, auc is %f' %(in_accuracy_ratio, in_accuracy_ratio/2+0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Group      Rate\n",
      "0      1  0.330097\n",
      "1      2  0.116505\n",
      "2      3  0.077670\n",
      "3      4  0.097087\n",
      "4      5  0.097087\n",
      "5      6  0.029126\n",
      "6      7  0.029126\n",
      "7      8  0.077670\n",
      "8      9  0.058252\n",
      "9     10  0.087379\n",
      "out-sample random forest accuracy ratio is 0.241300, auc is 0.620650\n"
     ]
    }
   ],
   "source": [
    "# out-sample rfr result \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "out_prob_,out_accuracy_ratio = get_prob_auc(clf_rfr, x_test,y_test)\n",
    "print (tencile_table(y_test,out_prob_))\n",
    "print ('out-sample random forest accuracy ratio is %f, auc is %f' %(out_accuracy_ratio, out_accuracy_ratio/2+0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
