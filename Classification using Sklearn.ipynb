{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use traditional method in sklearn to forecasting bankcruptcy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bankcruptcy prediction using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and align data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD for text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use SVD to reduce the dimension in the 10k text\n",
    "def generate_save_SVD():\n",
    "    X = np.load('data/10k/X_tfidf.npy')\n",
    "    text = pd.DataFrame(data=X)\n",
    "    svd = TruncatedSVD(n_components=80)\n",
    "    svd_text = svd.fit_transform(text)\n",
    "    print(svd.explained_variance_ratio_.sum())\n",
    "    np.save(\"data/10k/svd_X_80tfidf.npy\", svd_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121848, 5000)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NIAT', 'NISALE', 'OIADPAT', 'OIADPSALE', 'EBITAT', 'EBITDPAT', 'EBITSALE', 'SEQAT', 'REAT', 'LCTAT', 'LCTCHAT', 'LTAT', 'LOGSALE', 'CHAT', 'CHLCT', 'QALCT', 'ACTLCT', 'WCAPAT', 'LCTLT', 'INVTSALE', 'SALEAT', 'APSALE', 'LOGAT', 'INVCHINVT', 'CASHAT', 'LCTSALE', 'RELCT', 'FAT', 'SIGMA', 'NIMTA', 'LTMTA', 'CASHMTA', 'PRICE', 'RSIZE', 'EXCESS_RETURN', 'MBE']\n"
     ]
    }
   ],
   "source": [
    "# all numerical data\n",
    "final_variable = pd.read_csv('data/final_variables.csv')\n",
    "final_variable = final_variable.drop('Unnamed: 0',1)\n",
    "drop_list = ['gvkey','datadate','fyear','cusip','PERMNO','PERMCO', 'Y']\n",
    "all_x_var = list(final_variable.drop(drop_list, axis=1))\n",
    "print(all_x_var)\n",
    "lasso_x = ['PRICE','OIADPAT','NIMTA','FAT','LCTCHAT','EXCESS_RETURN','LCTAT','EBITDPAT'] # lasso selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions to load and align data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_train_split_year = 2011\n",
    "forecast_year = 1\n",
    "\n",
    "def n_year_before(df, n = 1):\n",
    "    \"\"\"input x,y df, return df with y and n year before x\"\"\"\n",
    "    dat_tmp = df.copy()\n",
    "    dat_tmp['fyear'] = dat_tmp['fyear'] + n\n",
    "    dat_tmp = dat_tmp.drop('Y',axis =1)\n",
    "    Ys = df[['fyear','gvkey','Y']]\n",
    "    n_year = pd.merge(dat_tmp,Ys,how = 'inner',on=['fyear','gvkey'])\n",
    "    return n_year\n",
    "\n",
    "def load_data(how='text', svd=True):\n",
    "    \"\"\"Input user specified method, return train_x, train_y, test_x, test_y based on pre-load df\n",
    "    :param how: ['text','numerical','total']\n",
    "    :type how: str\n",
    "    :param svd: do decomposition to tfidf\n",
    "    :type svd: boolean\n",
    "    :return: train_x, train_y, test_x, test_y split by fyear 2009\n",
    "    :rtype: pandas.dataframe\n",
    "    \"\"\"\n",
    "    print('Loading data')\n",
    "    \n",
    "    # load accounting and market data\n",
    "    final_variable = pd.read_csv('data/final_variables.csv')\n",
    "    final_variable = final_variable.drop('Unnamed: 0',1)\n",
    "    final_variable = final_variable.replace([np.inf,-np.inf],0)\n",
    "    final_variable = final_variable[final_variable['fyear'] >= 1993] # 10k data from 1993\n",
    "    final_variable.shape\n",
    "    # load 5000_tfidf text \n",
    "    total_text = pd.DataFrame(data=np.load('data/10k/X_tfidf.npy'))\n",
    "    print(\"10k data shape: \")\n",
    "    print(total_text.shape)\n",
    "    # load 80_tfidf text\n",
    "    svd_text = pd.DataFrame(data=np.load('data/10k/svd_X_80tfidf.npy'))\n",
    "    # load text index\n",
    "    index_10k = pd.read_csv('data/10k/10k_index.csv',usecols=['gvkey','fyear'])\n",
    "    print(\"10k index shape: \")\n",
    "    print(index_10k.shape)\n",
    "\n",
    "    if svd:\n",
    "        text = pd.concat([svd_text, index_10k], axis=1)\n",
    "        text_idx = list(range(80))\n",
    "    if not svd:\n",
    "        text = pd.concat([total_text, index_10k], axis=1)\n",
    "        text_idx = list(range(5000))\n",
    "    \n",
    "    \n",
    "    # combine text and numerical data\n",
    "    text_num = pd.merge(left=final_variable, right=text, how='inner', on=['gvkey','fyear'])\n",
    "    print(\"Total number of observations with no forecasting: \")\n",
    "    print(text_num.shape)\n",
    "    text_num_n_year = n_year_before(text_num, n = forecast_year)\n",
    "    print(\"Total number of observations: \")\n",
    "    print(text_num_n_year.shape)\n",
    "    text_num_n_year.fillna(0, inplace=True)\n",
    "    \n",
    "    train = text_num_n_year[text_num_n_year['fyear'] < test_train_split_year]\n",
    "    test = text_num_n_year[text_num_n_year['fyear'] >= test_train_split_year]\n",
    "    train_y = train['Y']\n",
    "    test_y = test['Y']\n",
    "\n",
    "    if how == 'text':\n",
    "        train_x = train.ix[:,text_idx]\n",
    "        test_x = test.ix[:,text_idx]                       \n",
    "    if how == 'num':\n",
    "        # use 8 selected numerical features\n",
    "        train_x = train[all_x_var]\n",
    "        test_x = test[all_x_var]\n",
    "    if how == 'total':\n",
    "        train_x = pd.concat([train.ix[:,text_idx],train[all_x_var]], axis=1) \n",
    "        test_x = pd.concat([test.ix[:,text_idx],test[all_x_var]], axis=1) \n",
    "    print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)\n",
    "    print(train_x.head(5))\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "def get_prob_auc(clf,x,y):\n",
    "    probas_= clf.predict_proba(x)\n",
    "    probas_=probas_[:,1]\n",
    "    fpr,tpr,thresholds = roc_curve(y,probas_)\n",
    "    roc_auc = roc_auc_score(y,probas_)\n",
    "    accuracy_ratio = (roc_auc-0.5)*2\n",
    "    return probas_,accuracy_ratio\n",
    "\n",
    "def tencile_table(test,p):\n",
    "    tenc_dat = pd.DataFrame({'y_true':test,'probability':p})\n",
    "    tenc_dat.sort('probability',axis = 0,ascending=False, inplace = True)\n",
    "    tenc_dat.index = range(0,len(tenc_dat))\n",
    "    y = tenc_dat['y_true']\n",
    "    point = float(len(tenc_dat))/10\n",
    "    point = int(round(point))\n",
    "    tenc = []\n",
    "    for i in range(0,10):\n",
    "        tenc.append(y[(i*point):((i+1)*point)])\n",
    "    tenc[9]=tenc[9].append(y[10*point:])\n",
    "    total = sum(y)\n",
    "    num_of_bkr = []\n",
    "    for j in range(0,10):\n",
    "        num_of_bkr.append(sum(tenc[j]))\n",
    "    tencile_bkr = np.array(num_of_bkr)\n",
    "    rate = tencile_bkr.astype(float)/total\n",
    "    tencile_result=pd.DataFrame({'Group':range(1,11),'Rate':rate})\n",
    "    return tencile_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(model_type):\n",
    "    # create your model using this function\n",
    "    if model_type == 'MNB':\n",
    "        model = MultinomialNB()\n",
    "    if model_type == 'lg':\n",
    "        model = LogisticRegression(C = 0.18,penalty='l1')\n",
    "#         model = LogisticRegressionCV(Cs = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], solver = 'liblinear',\n",
    "#                                      penalty='l1')\n",
    "    if model_type == 'lg-text':\n",
    "        model = LogisticRegression(C = 0.017,penalty='l1')\n",
    "    if model_type =='SVM':\n",
    "        model = LinearSVC(C=0.000004)\n",
    "    if model_type == 'GNB':\n",
    "        model = GaussianNB()\n",
    "    if model_type == 'SVM_rbf':\n",
    "        model = SVC(kernel='rbf', C=0.005, class_weight='balanced')\n",
    "    if model_type == 'SVM_poly':\n",
    "        model = SVC(kernel='poly', C=0.001)\n",
    "    if model_type == 'random_forest':\n",
    "        model = RandomForestClassifier(max_depth=8)\n",
    "    if model_type == \"boost\":\n",
    "        model = GradientBoostingClassifier()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only look at single models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method is:  ('text', 'boost')\n",
      "Loading data\n",
      "10k data shape: \n",
      "(121848, 5000)\n",
      "10k index shape: \n",
      "(121848, 2)\n",
      "Total number of observations with no forecasting: \n",
      "(79222, 5043)\n",
      "Total number of observations: \n",
      "(64999, 5043)\n",
      "(50286, 5000) (50286,) (14713, 5000) (14713,)\n",
      "   0         1         2         3         4         5         6         7     \\\n",
      "4   0.0  5.143531  4.822726  4.754027  4.548103  4.644117  4.229583  4.115143   \n",
      "5   0.0  5.143531  4.803432  4.771720  4.562860  4.696352  4.087589  4.094556   \n",
      "6   0.0  5.161100  4.726078  4.664173  4.512507  4.689111  4.076383  4.104918   \n",
      "7   0.0  5.174858  4.783604  4.669951  4.502021  4.632429  4.283316  3.982480   \n",
      "8   0.0  4.649827  4.474391  4.472400  4.310765  4.244091  4.029873  3.791913   \n",
      "\n",
      "       8         9     ...       4990      4991  4992  4993  4994  4995  \\\n",
      "4  5.074887  0.879722  ...   0.000000  3.251397   0.0   0.0   0.0   0.0   \n",
      "5  5.175413  0.000000  ...   0.000000  3.251397   0.0   0.0   0.0   0.0   \n",
      "6  5.026521  0.000000  ...   0.000000  3.251397   0.0   0.0   0.0   0.0   \n",
      "7  5.109601  0.000000  ...   3.379065  3.251397   0.0   0.0   0.0   0.0   \n",
      "8  4.849629  0.000000  ...   3.379065  5.505094   0.0   0.0   0.0   0.0   \n",
      "\n",
      "       4996  4997  4998  4999  \n",
      "4  0.000000   0.0   0.0   0.0  \n",
      "5  0.000000   0.0   0.0   0.0  \n",
      "6  0.000000   0.0   0.0   0.0  \n",
      "7  3.431275   0.0   0.0   0.0  \n",
      "8  3.431275   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 5000 columns]\n"
     ]
    }
   ],
   "source": [
    "method = ('text','boost')\n",
    "\n",
    "print('method is: ', method)\n",
    "train_x, train_y, test_x, test_y = load_data(how=method[0], svd=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in sample result:\n",
      "0.898879230754\n",
      "out sample result:\n",
      "0.576911294166\n"
     ]
    }
   ],
   "source": [
    "print('in sample result:')\n",
    "model = create_model(model_type=method[1])\n",
    "model.fit(train_x, train_y)\n",
    "if hasattr(model, 'predict_proba'):\n",
    "    pred_yp = model.predict_proba(train_x)[:,1]\n",
    "else:\n",
    "    pred_yp = model.decision_function(train_x)\n",
    "    pred_yp = (pred_yp - pred_yp.min()) / (pred_yp.max() - pred_yp.min())\n",
    "roc = metrics.roc_auc_score(train_y, pred_yp)\n",
    "print(roc)\n",
    "print('out sample result:')\n",
    "model = create_model(model_type=method[1])\n",
    "model.fit(train_x, train_y)\n",
    "if hasattr(model, 'predict_proba'):\n",
    "    pred_yp = model.predict_proba(test_x)[:,1]\n",
    "else:\n",
    "    pred_yp = model.decision_function(test_x)\n",
    "    pred_yp = (pred_yp - pred_yp.min()) / (pred_yp.max() - pred_yp.min())\n",
    "roc = metrics.roc_auc_score(test_y, pred_yp)\n",
    "print(roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Benchmark multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#80 tfidf result, max_depth=1, n_estimators=150\n",
    "methods = [('text','MNB'),('numerical','lg'),('total','random_forest')]\n",
    "# for method in methods:\n",
    "#     print('method is: ', method)\n",
    "#     train_x, train_y, test_x, test_y = load_data(how=method[0], svd=False)\n",
    "#     print('in sample result:')\n",
    "#     model = create_model(model_type=method[1])\n",
    "#     model.fit(train_x, train_y)\n",
    "#     if hasattr(model, 'predict_proba'):\n",
    "#         pred_yp = model.predict_proba(train_x)[:,1]\n",
    "#     else:\n",
    "#         pred_yp = model.decision_function(train_x)\n",
    "#         pred_yp = (pred_yp - pred_yp.min()) / (pred_yp.max() - pred_yp.min())\n",
    "#     roc = metrics.roc_auc_score(train_y, pred_yp)\n",
    "#     print(roc)\n",
    "#     print('out sample result:')\n",
    "#     model = create_model(model_type=method[1])\n",
    "#     model.fit(train_x, train_y)\n",
    "#     if hasattr(model, 'predict_proba'):\n",
    "#         pred_yp = model.predict_proba(test_x)[:,1]\n",
    "#     else:\n",
    "#         pred_yp = model.decision_function(test_x)\n",
    "#         pred_yp = (pred_yp - pred_yp.min()) / (pred_yp.max() - pred_yp.min())\n",
    "#     roc = metrics.roc_auc_score(test_y, pred_yp)\n",
    "#     print(roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_x.shape[0] + test_x.shape[0]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
